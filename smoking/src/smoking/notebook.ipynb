{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 12:08:29.809415: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-20 12:08:29.809471: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-20 12:08:29.810659: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-20 12:08:29.820548: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 12:08:30.909504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect\n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import regularizers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_input_output(df, input_cols=None, output_cols=None, remove_cols=None):\n",
    "    if remove_cols is None:\n",
    "        remove_cols = ['id']\n",
    "    if output_cols is None:\n",
    "        output_cols = ['smoking']\n",
    "    if input_cols is None:\n",
    "        input_cols = [c for c in df.columns if c not in remove_cols and c not in output_cols]\n",
    "    X = df[input_cols].values\n",
    "    y = df[output_cols].values\n",
    "    shape = (y.shape[0],)\n",
    "    data = {\n",
    "        'X': X,\n",
    "        'y': y.reshape(shape),\n",
    "        'columns': input_cols\n",
    "    }\n",
    "    return data\n",
    "\n",
    "def scaler_preprocess(X):\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X_processed = scaler.transform(X)\n",
    "\n",
    "    data = {\n",
    "        'X': X_processed,\n",
    "    }\n",
    "    return data\n",
    "\n",
    "def PCA_preprocess(X):\n",
    "    X_PCA = PCA().fit_transform(X)\n",
    "    X_processed = np.concatenate([X, X_PCA], axis=1)\n",
    "    data = {\n",
    "        'X': X_processed,\n",
    "    }\n",
    "    return data\n",
    "\n",
    "def preprocess_eyesight(df):\n",
    "\n",
    "    cols = ['eyesight(left)', 'eyesight(right)']\n",
    "    df.loc[:, 'best_eyesight_is_left'] = False\n",
    "    df.loc[:, 'best_eyesight_is_right'] = False\n",
    "\n",
    "    df.loc[df['eyesight(left)'] > df['eyesight(right)'], 'best_eyesight_is_left'] = True\n",
    "    df.loc[df['eyesight(left)'] < df['eyesight(right)'], 'best_eyesight_is_right'] = True\n",
    "    # values = df[cols].values.flatten()\n",
    "    # thermos = generate_thermos(values)\n",
    "    # for key, value in thermos:\n",
    "    #     df.loc[:, f'eyesight(left)_{key}'] = False\n",
    "    #     df.loc[:, f'eyesight(right)_{key}'] = False\n",
    "    #     df.loc[df['eyesight(left)'] >= value, f'eyesight(left)_{key}'] = True\n",
    "    #     df.loc[df['eyesight(right)'] >= value, f'eyesight(right)_{key}'] = True\n",
    "\n",
    "    df.drop(cols, axis=1, inplace=True)\n",
    "    df.fillna(True, inplace=True)\n",
    "\n",
    "    data = {'df': df}\n",
    "    return data\n",
    "\n",
    "def preprocess_hearing(df):\n",
    "\n",
    "    df.loc[:, 'best_hearing_is_left'] = df['hearing(left)'] > df['hearing(right)']\n",
    "    df.loc[:, 'best_hearing_is_right'] = df['hearing(left)'] < df['hearing(right)']\n",
    "    df.loc[:, 'hearing(left)'] = df.loc[:, 'hearing(left)'] - 1\n",
    "    df.loc[:, 'hearing(right)'] = df.loc[:, 'hearing(right)'] - 1\n",
    "\n",
    "    data = {'df':df}\n",
    "\n",
    "    return data\n",
    "\n",
    "def preprocess_thermos(df, thermos_columns=None):\n",
    "    if thermos_columns is None:\n",
    "        thermos_columns = ['weight(kg)', 'waist(cm)', 'systolic', 'age', 'height(cm)',\n",
    "        'relaxation', 'fasting blood sugar', 'Cholesterol', 'triglyceride',\n",
    "        'HDL', 'LDL', 'hemoglobin', 'serum creatinine', 'AST', 'ALT', 'Gtp']\n",
    "    for col in thermos_columns:\n",
    "        values = df[col].values.flatten()\n",
    "        thermos = generate_thermos(values)\n",
    "        for key, value in thermos:\n",
    "            df.loc[:, f'{col}_{key}'] = False\n",
    "            df.loc[df[col] >= value, f'{col}_{key}'] = True\n",
    "    df.drop(thermos_columns, axis=1, inplace=True)\n",
    "\n",
    "    data = {\n",
    "        'df':df\n",
    "    }\n",
    "    return data\n",
    "\n",
    "def preprocess_one_hot(df, one_hot_columns=None):\n",
    "    if one_hot_columns is None:\n",
    "        one_hot_columns = ['Urine protein']\n",
    "    for col in one_hot_columns:\n",
    "        values = df[col].unique()\n",
    "        thermos = generate_one_hot(values)\n",
    "        for key, value in thermos:\n",
    "            df.loc[:, f'{col}_{key}'] = df[col] == value\n",
    "    df.drop(one_hot_columns, axis=1, inplace=True)\n",
    "    data = {\n",
    "        'df':df\n",
    "    }\n",
    "    return data\n",
    "def generate_thermos(values):\n",
    "    percentiles = set(np.percentile(values, [i for i in range(0,100, 10)]))\n",
    "    percentiles = [a for a in enumerate(percentiles)]\n",
    "\n",
    "    percentiles.sort(key=lambda x: x[1])\n",
    "    return percentiles\n",
    "\n",
    "def generate_one_hot(values):\n",
    "    one_hot_values = set(values)\n",
    "    one_hot_values = [a for a in enumerate(one_hot_values)]\n",
    "    return one_hot_values\n",
    "\n",
    "def preprocess(df, preprocessing_functions):\n",
    "    input_data = {'df': df}\n",
    "\n",
    "    for f in preprocessing_functions:\n",
    "        args = inspect.getfullargspec(f).args\n",
    "        sub_input = {k: input_data[k] for k in args if k in input_data}\n",
    "        res = f(**sub_input)\n",
    "        input_data.update(res)\n",
    "\n",
    "    return input_data['X'], input_data['y'], input_data['columns']\n",
    "\n",
    "def get_MLPClassifier_for_grid_search():\n",
    "    alphas = [0.1, 0.15, 0.25]\n",
    "    layers = [(300, 100, i) for i in range(10, 60, 10)]\n",
    "\n",
    "    parameters = {'alpha': alphas, 'hidden_layer_sizes': layers}\n",
    "    clf = MLPClassifier()\n",
    "    return 'MLPC', clf, parameters\n",
    "\n",
    "def get_keras_MLPClassifier_for_grid_search():\n",
    "    clf = KerasClassifier(\n",
    "        model=get_clf_model,\n",
    "        hidden_layer_sizes=(100,),\n",
    "        optimizer=\"adam\",\n",
    "        optimizer__learning_rate=0.001,\n",
    "        epochs=50,\n",
    "        verbose=0,\n",
    "    )\n",
    "def print_grid_search_results(results):\n",
    "    params_with_values = [(p, m, s) for p, m, s in\n",
    "                          zip(results['params'], results['mean_test_AUC'], results['std_test_AUC'])]\n",
    "    best_result = np.argmin(results['rank_test_AUC'])\n",
    "    winner_params = params_with_values[best_result]\n",
    "    winner_params_str = \" \".join([f\"{key}: {value}\" for key, value in winner_params[0].items()])\n",
    "    print(f'Winner is [{winner_params_str}] {winner_params[1]:.4f} mean. {winner_params[2]:.2f} std')\n",
    "    for params, mean, std in params_with_values:\n",
    "        params_str = \" \".join([f\"{key}: {value}\" for key, value in params.items()])\n",
    "        print(f\"[{params_str}] {mean:.4f} mean. {std:.2f} std\")\n",
    "\n",
    "def estandar(cols):\n",
    "\t# create model\n",
    "    model = Sequential()\n",
    "    model.add(Input((cols,)))\n",
    "    model.add(Dense(300, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
    "    model.add(Dense(30, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "    return lambda : model\n",
    "\n",
    "def deep(cols):\n",
    "\t# create model\n",
    "    model = Sequential()\n",
    "    model.add(Input((cols,)))\n",
    "    model.add(Dense(30, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
    "    model.add(Dense(30, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
    "    model.add(Dense(30, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
    "    model.add(Dense(30, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "    return lambda : model\n",
    "\n",
    "def get_KerasClassifier_for_grid_search(cols):\n",
    "    es = callbacks.EarlyStopping()\n",
    "    clf = KerasClassifier(verbose=3, callbacks=[es])\n",
    "    return \"Keras\", clf, {'model':[deep(cols), estandar(cols)], 'epochs': [5], 'batch_size': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>...</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>165</td>\n",
       "      <td>65</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>126</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>93</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>180</td>\n",
       "      <td>95</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>102</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>93</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159251</th>\n",
       "      <td>159251</td>\n",
       "      <td>40</td>\n",
       "      <td>155</td>\n",
       "      <td>45</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>159</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159252</th>\n",
       "      <td>159252</td>\n",
       "      <td>50</td>\n",
       "      <td>155</td>\n",
       "      <td>75</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>108</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159253</th>\n",
       "      <td>159253</td>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159254</th>\n",
       "      <td>159254</td>\n",
       "      <td>50</td>\n",
       "      <td>165</td>\n",
       "      <td>75</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>80</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159255</th>\n",
       "      <td>159255</td>\n",
       "      <td>40</td>\n",
       "      <td>145</td>\n",
       "      <td>45</td>\n",
       "      <td>76.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>81</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159256 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
       "0            0   55         165          60       81.0             0.5   \n",
       "1            1   70         165          65       89.0             0.6   \n",
       "2            2   20         170          75       81.0             0.4   \n",
       "3            3   35         180          95      105.0             1.5   \n",
       "4            4   30         165          60       80.5             1.5   \n",
       "...        ...  ...         ...         ...        ...             ...   \n",
       "159251  159251   40         155          45       69.0             1.5   \n",
       "159252  159252   50         155          75       82.0             1.0   \n",
       "159253  159253   40         160          50       66.0             1.5   \n",
       "159254  159254   50         165          75       92.0             1.2   \n",
       "159255  159255   40         145          45       76.4             1.0   \n",
       "\n",
       "        eyesight(right)  hearing(left)  hearing(right)  systolic  ...  HDL  \\\n",
       "0                   0.6              1               1       135  ...   40   \n",
       "1                   0.7              2               2       146  ...   57   \n",
       "2                   0.5              1               1       118  ...   45   \n",
       "3                   1.2              1               1       131  ...   38   \n",
       "4                   1.0              1               1       121  ...   44   \n",
       "...                 ...            ...             ...       ...  ...  ...   \n",
       "159251              2.0              1               1       127  ...   72   \n",
       "159252              1.0              1               1       120  ...   64   \n",
       "159253              1.0              1               1       114  ...   87   \n",
       "159254              1.0              1               1       121  ...   55   \n",
       "159255              1.2              1               1       125  ...   87   \n",
       "\n",
       "        LDL  hemoglobin  Urine protein  serum creatinine  AST  ALT  Gtp  \\\n",
       "0        75        16.5              1               1.0   22   25   27   \n",
       "1       126        16.2              1               1.1   27   23   37   \n",
       "2        93        17.4              1               0.8   27   31   53   \n",
       "3       102        15.9              1               1.0   20   27   30   \n",
       "4        93        15.4              1               0.8   19   13   17   \n",
       "...     ...         ...            ...               ...  ...  ...  ...   \n",
       "159251  159        14.5              1               0.8   25   26   13   \n",
       "159252  108        14.5              1               0.6   21   20   18   \n",
       "159253   93        10.9              1               0.6   15    9   12   \n",
       "159254   80        14.4              1               1.1   22   17   37   \n",
       "159255   81        14.0              1               0.8   21   16   17   \n",
       "\n",
       "        dental caries  smoking  \n",
       "0                   0        1  \n",
       "1                   1        0  \n",
       "2                   0        1  \n",
       "3                   1        0  \n",
       "4                   0        1  \n",
       "...               ...      ...  \n",
       "159251              0        0  \n",
       "159252              0        0  \n",
       "159253              0        0  \n",
       "159254              0        1  \n",
       "159255              0        0  \n",
       "\n",
       "[159256 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/smoking/train.csv')\n",
    "\n",
    "# Train dataset has the column that indicates that the person is a smoker or not.\n",
    "# The idea is to use this dataset to train and tune our model, once trained we use the same model to classify test.csv which doesn't have the \"smokes\" column. This is not done on this notebook.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We preprocess the dataset in different ways so it is easier to handle and provides better results\n",
    "preprocessing_functions = [\n",
    "    preprocess_eyesight,\n",
    "    preprocess_hearing,\n",
    "    #preprocess_thermos,\n",
    "    preprocess_one_hot,\n",
    "    get_input_output,\n",
    "    scaler_preprocess\n",
    "]\n",
    "X, y, cols = preprocess(df, preprocessing_functions)\n",
    "\n",
    "# We generate different classifiers to see which one performs the best. Each classifier has its own parameters to explore, so we do a grid search: https://en.wikipedia.org/wiki/Hyperparameter_optimization to look for the most performant.\n",
    "classifiers_to_explore = [\n",
    "    #get_MLPClassifier_for_grid_search(),\n",
    "    get_KerasClassifier_for_grid_search(len(cols))\n",
    "]\n",
    "for name, clf, parameters in classifiers_to_explore:\n",
    "    # For each classifier we do a grid search for all its parameters\n",
    "    gs = GridSearchCV(clf, parameters, n_jobs=1, scoring={\"AUC\":\"roc_auc\"}, refit=\"AUC\", return_train_score=True, verbose=3)\n",
    "\n",
    "    gs.fit(X, y)\n",
    "    results = gs.cv_results_\n",
    "    print(name)\n",
    "    print_grid_search_results(results)\n",
    "\n",
    "# The best classifier should have the better score at the end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
